name: Build and Deploy Snapshot
on: [push]
permissions:
  contents: read

jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        # JDK 17 has a few failures so cannot yet enable for this module
        java_version: ['8', '11']
        os: ['ubuntu-20.04']
    env:
      JAVA_OPTS: "-XX:+TieredCompilation -XX:TieredStopAtLevel=1"
    steps:
    - uses: actions/setup-python@v2
      with:
        python-version: '3.10'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas
        pip install numpy
    - run: sudo apt update
    - run: sudo apt install inotify-tools
    - run: inotifywait -mr /home/runner/work/jackson-databind/jackson-databind/ --format '%T;%w;%f;%e' --timefmt %T -o /home/runner/inotify-logs.csv & echo 'basak'
    - run: touch starting_build_uses34_34
    - run: rm starting_build_uses34_34
    - uses: actions/checkout@v3
    - run: touch starting_build_SetupJDK_35
    - run: rm starting_build_SetupJDK_35
    - name: Set up JDK
      uses: actions/setup-java@v3
      with:
        distribution: 'temurin'
        java-version: ${{ matrix.java_version }}
        cache: 'maven'
        server-id: sonatype-nexus-snapshots
        server-username: CI_DEPLOY_USERNAME
        server-password: CI_DEPLOY_PASSWORD
        # See https://github.com/actions/setup-java/blob/v2/docs/advanced-usage.md#Publishing-using-Apache-Maven
        # gpg-private-key: ${{ secrets.MAVEN_GPG_PRIVATE_KEY }} # Value of the GPG private key to import
        # gpg-passphrase: MAVEN_GPG_PASSPHRASE # env variable for GPG private key passphrase
    - run: touch starting_build_Build_47
    - run: rm starting_build_Build_47
    - name: Build
      run: ./mvnw -B -ff -ntp clean verify
    - run: touch starting_build_ExtractprojectMavenversion_49
    - run: rm starting_build_ExtractprojectMavenversion_49
    - name: Extract project Maven version
      id: projectVersion
      run: echo ::set-output name=version::$(./mvnw org.apache.maven.plugins:maven-help-plugin:3.2.0:evaluate -DforceStdout -Dexpression=project.version -q)
    - run: touch starting_build_Deploysnapshot_52
    - run: rm starting_build_Deploysnapshot_52
    - name: Deploy snapshot
      if: github.event_name != 'pull_request' && matrix.java_version == '8' && endsWith(steps.projectVersion.outputs.version, '-SNAPSHOT')
      env:
        CI_DEPLOY_USERNAME: ${{ secrets.CI_DEPLOY_USERNAME }}
        CI_DEPLOY_PASSWORD: ${{ secrets.CI_DEPLOY_PASSWORD }}
        # MAVEN_GPG_PASSPHRASE: ${{ secrets.MAVEN_GPG_PASSPHRASE }}
      run: ./mvnw -B -q -ff -DskipTests -ntp source:jar deploy
    - run: touch starting_build_Generatecodecoverage_59
    - run: rm starting_build_Generatecodecoverage_59
    - name: Generate code coverage
      if: github.event_name != 'pull_request' && matrix.java_version == '8'
      run: ./mvnw -B -q -ff -ntp test
    - run: touch starting_build_Publishcodecoverage_62
    - run: rm starting_build_Publishcodecoverage_62
    - name: Publish code coverage
      if: github.event_name != 'pull_request' && matrix.java_version == '8'
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./target/site/jacoco/jacoco.xml
        flags: unittests
    - run: touch starting_finished_finished_8979874
    - run: rm starting_finished_finished_8979874
    - uses: jannekem/run-python-script-action@v1
      with:
        script: |
          import pandas as pd
          import numpy as np
          import os
          df = pd.read_csv('/home/runner/inotify-logs.csv', sep = ';', names=['time', 'watched_filename', 'event_filename', 'event_name'])
          df['event_filename'] = df['event_filename'].replace(np.nan, '')
          steps = {}
          starting_indexes = df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CREATE')].index.to_list() + [df.shape[0]]
          ending_indexes = [0] + df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'DELETE')].index.to_list()
          starting_df = df[df['event_filename'].str.contains('starting_')]
          touch_file_names = ['setup'] + [x.replace('starting_', '') for x in starting_df['event_filename'].value_counts().index.to_list()]
          for starting_index, ending_index, touch_file_name in zip(starting_indexes, ending_indexes, touch_file_names):
              steps[touch_file_name] = (ending_index, starting_index)
          df['watched_filename'] = df['watched_filename'] + df['event_filename']
          df.drop('event_filename', axis=1, inplace=True)
          df.rename(columns={'watched_filename':'file_name'}, inplace=True)
          modify_df = df[df['event_name'] == 'MODIFY']
          file_names = modify_df['file_name'].value_counts().index.to_list()
          info = []
          for file_name in file_names:
              last_access_step = ''
              last_modify_step = ''
              creation_step = ''
              if df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].shape[0] == 0: last_modify_index = -1
              else: last_modify_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].index.to_list()[-1]
              last_access_index = 0
              if df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].shape[0] > 0:
                  last_access_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].index.to_list()[-1]
              else:
                  last_access_index = -1
                  last_access_step = 'Not provided'
              if last_access_index < last_modify_index:
                  try:
                      creation_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'CREATE')].index.to_list()[0]
                  except:
                      creation_index = -1
                      creation_step = 'Not provided'
                  for touch_file_name, (starting_index, ending_index) in steps.items():
                      if (last_access_index > starting_index) and (last_access_index < ending_index):
                          last_access_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                      if (last_modify_index > starting_index) and (last_modify_index < ending_index):
                          last_modify_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                      if (creation_index > starting_index) and (creation_index < ending_index):
                          creation_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                  if '/home/runner/work/jackson-databind/jackson-databind/.git/' not in file_name:
                      info.append({'file_name': file_name, 'last_access_index': last_access_index, 'last_modify_index': last_modify_index, 'creation_index': creation_index, 'last_access_step':last_access_step , 'last_modify_step':last_modify_step, 'creation_step': creation_step})
          info_df = pd.DataFrame(info)
          step_statistics = []
          for step, (starting_index, ending_index) in steps.items():
              step_name = step if step == 'setup' else step.split('_')[1]
              if step_name == 'finished': continue
              c = info_df['creation_step'] == step_name
              m = info_df['last_modify_step'] == step_name
              a = info_df['last_access_index'] > -1
              t = info_df['last_access_index'] > info_df['last_modify_index'] # never accessed after last modify (but accessed at least once)
              cma = info_df[c & m & a].shape[0]
              cma_ = info_df[c & m & ~a].shape[0]
              cmt = info_df[c & m & t].shape[0]
              cm_a = info_df[c & ~m & a].shape[0]
              cm_a_ = info_df[c & ~m & ~a].shape[0]
              cm_t = info_df[c & ~m & t].shape[0]
              c_ma = info_df[~c & m & a].shape[0]
              c_ma_ = info_df[~c & m & ~a].shape[0]
              c_mt = info_df[~c & m & t].shape[0]
              c_m_a = info_df[~c & ~m & a].shape[0]
              c_m_a_ = info_df[~c & ~m & ~a].shape[0]
              c_m_t = info_df[~c & ~m & t].shape[0]
              created_file_count = info_df[c].shape[0]
              modified_file_count = info_df[m].shape[0]
              starting_time = list(map(int, df.iloc[starting_index]['time'].split(':')))
              if ending_index == len(df): ending_time = list(map(int, df.iloc[ending_index-1]['time'].split(':')))
              else: ending_time = list(map(int, df.iloc[ending_index]['time'].split(':')))
              hour = ending_time[0] - starting_time[0]
              if starting_time[1] > ending_time[1]:
                  minute = ending_time[1] - starting_time[1] + 60
                  hour -= 1
              else: minute = ending_time[1] - starting_time[1]
              if starting_time[2] > ending_time[2]:
                  second = ending_time[2] - starting_time[2] + 60
                  minute -= 1
              else: second = ending_time[2] - starting_time[2]
              total_seconds = second + (minute * 60) + (hour * 60 * 60)
              if step_name != '':
                  step_statistics.append({'step_name': step_name, '#c': created_file_count, '#m': modified_file_count, 
                  'cma': cma, 'cma_': cma_, 'cmt': cmt, 'cm_a': cm_a, 'cm_a_': cm_a_, 'cm_t': cm_t, 'c_ma': c_ma, 'c_ma_': c_ma_, 'c_mt': c_mt, 'c_m_a': c_m_a, 'c_m_a_': c_m_a_, 'c_m_t': c_m_t, 'time': total_seconds})
          os.mkdir('optimizing-ci-builds-ci-analysis')
          step_df = pd.DataFrame(step_statistics)
          step_df.to_csv('/home/runner/work/jackson-databind/jackson-databind/optimizing-ci-builds-ci-analysis/steps.csv')
          info_df.to_csv('/home/runner/work/jackson-databind/jackson-databind/optimizing-ci-builds-ci-analysis/files.csv')
    - run: cp /home/runner/inotify-logs.csv /home/runner/work/jackson-databind/jackson-databind/optimizing-ci-builds-ci-analysis/
    - name: Pushes analysis to another repository
      id: push_directory
      uses: cpina/github-action-push-to-another-repository@main
      env:
        API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
      with:
        source-directory: 'optimizing-ci-builds-ci-analysis'
        destination-github-username: 'optimizing-ci-builds'
        destination-repository-name: 'ci-analyzes'
        target-directory: 'jackson-databind/1666737283/.github/workflows/main/build'

